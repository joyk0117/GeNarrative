#!/usr/bin/env python3
"""
Unified SIS (formerly SIS) to Content Generation Script

çµ±ä¸€ã•ã‚ŒãŸå®Ÿè£…æ–¹é‡ã«ã‚ˆã‚‹ã€SISãƒ‡ãƒ¼ã‚¿ï¼ˆæ—§ç§°SISï¼‰ã‹ã‚‰ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç”Ÿæˆæ©Ÿèƒ½
- çµ±ä¸€ã•ã‚ŒãŸã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
- è¨­å®šã‚¯ãƒ©ã‚¹ã«ã‚ˆã‚‹è¨­å®šç®¡ç†
- çµ±ä¸€ã•ã‚ŒãŸã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã¨æˆ»ã‚Šå€¤æ§‹é€ 
- æ”¹è‰¯ã•ã‚ŒãŸãƒ­ã‚°ã‚·ã‚¹ãƒ†ãƒ 

Usage:
    python _unified.py --mode image [--sis_file path/to/sis.json] [--width 512] [--height 512]
    python _unified.py --mode music [--sis_file path/to/sis.json] [--duration 30]
    python _unified.py --mode text [--sis_file path/to/sis.json] [--word_count 50]
    python _unified.py --mode tts [--sis_file path/to/sis.json] [--text_input "Direct text"] [--output_filename speech]
"""

import os
import sys
import json
import requests
import time
import argparse
import base64
import shutil
import re
from datetime import datetime
from typing import Dict, Any, Optional
from pathlib import Path
from functools import lru_cache
from string import Template

# å…±é€šåŸºç›¤ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from common_base import (
    APIConfig, ProcessingConfig, GenerationConfig,
    ContentProcessor, ProcessingResult, StructuredLogger,
    GeNarrativeError, FileProcessingError, ServerConnectionError, 
    ModelNotLoadedError, ContentTypeError, ValidationError,
    create_standard_response
)


PROMPT_DIR = Path(__file__).parent / 'prompts'


@lru_cache(maxsize=16)
def _load_prompt_template(filename: str) -> Template:
    """Load and cache prompt templates stored under ui/scripts/prompts."""
    template_path = PROMPT_DIR / filename
    if not template_path.exists():
        raise FileNotFoundError(f"Prompt template not found: {template_path}")
    with open(template_path, 'r', encoding='utf-8') as prompt_file:
        return Template(prompt_file.read())


# ========================================
# ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç”Ÿæˆãƒ—ãƒ­ã‚»ãƒƒã‚µã‚¯ãƒ©ã‚¹
# ========================================

class ContentGenerator(ContentProcessor):
    """çµ±ä¸€ã•ã‚ŒãŸã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç”Ÿæˆã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, 
                 api_config: Optional[APIConfig] = None,
                 processing_config: Optional[ProcessingConfig] = None,
                 generation_config: Optional[GenerationConfig] = None,
                 logger: Optional[StructuredLogger] = None):
        super().__init__(api_config, processing_config, logger)
        self.generation_config = generation_config or GenerationConfig()
    
    def process(self, sis_data: Dict[str, Any], content_type: str, **kwargs) -> ProcessingResult:
        """çµ±åˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç”Ÿæˆå‡¦ç†"""
        function_name = 'generate_content'
        
        try:
            # å‡¦ç†é–‹å§‹
            self._start_processing(function_name, {
                'content_type': content_type,
                'sis_summary': sis_data.get('summary', 'N/A')[:100]
            })
            
            # SIS ãƒ‡ãƒ¼ã‚¿ã®æ­£è¦åŒ–ï¼ˆsemanticsãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒã‚ã‚‹å ´åˆã¯å±•é–‹ï¼‰
            sis_data = self._normalize_sis_data(sis_data)
            
            # SIS ãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼
            self._validate_sis_data(sis_data)
            
            # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¿ã‚¤ãƒ—ã®æ¤œè¨¼
            if content_type not in ['image', 'music', 'text']:
                raise ContentTypeError(content_type, ['image', 'music', 'text'])
            
            # ç”»åƒç”Ÿæˆã®å ´åˆã®ç‰¹åˆ¥å‡¦ç†ï¼šSDã‚µãƒ¼ãƒãƒ¼ãŒåˆ©ç”¨å¯èƒ½ã§UnslothãŒåˆ©ç”¨ä¸å¯ã®å ´åˆ
            if content_type == "image":
                unsloth_available = self._is_unsloth_available()
                sd_available = self._check_sd_server()
                
                self.logger.logger.info(f"ğŸ” Server availability check - Unsloth: {unsloth_available}, SD: {sd_available}")
                
                if sd_available and not unsloth_available:
                    self.logger.logger.info("ğŸ–¼ï¸ Using direct SD generation (Unsloth not available)")
                    return self._generate_image_directly(sis_data, **kwargs)
                elif not sd_available:
                    raise GeNarrativeError("SD server is not available for image generation")
                else:
                    self.logger.logger.info("ğŸ¤– Using Unsloth + SD pipeline")
            
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
            prompt = self._create_prompt(sis_data, content_type, **kwargs)

            # ç”Ÿæˆã‚¨ãƒ³ã‚¸ãƒ³ã®é¸æŠ
            if content_type in ("text", "music", "image"):
                # ãƒ†ã‚­ã‚¹ãƒˆ/éŸ³æ¥½/ç”»åƒç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯ Ollama çµŒç”±ã§ç”Ÿæˆï¼ˆUnsloth ä¸ä½¿ç”¨ï¼‰
                generated_text = self._generate_with_ollama(prompt)
            else:
                # å¿µã®ãŸã‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆé€šå¸¸åˆ°é”ã—ãªã„ï¼‰
                generated_text = self._generate_with_ollama(prompt)
            
            # çµæœã®ä¿å­˜
            output_path = self._save_generated_content(
                generated_text, content_type, **kwargs
            )
            
            # è¿½åŠ ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç”Ÿæˆï¼ˆç”»åƒãƒ»éŸ³æ¥½ï¼‰
            # skip_actual_generation=True ã®å ´åˆã¯ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆã®ã¿ã§çµ‚äº†
            if kwargs.get('skip_actual_generation'):
                self.logger.logger.info("â­ï¸ Skipping actual generation (prompt-only mode)")
                additional_results = {}
            else:
                additional_results = self._generate_additional_content(
                    generated_text, content_type, **kwargs
                )
            
            # å‡¦ç†çµ‚äº†
            duration = self._end_processing(function_name, True)
            
            # çµæœãƒ‡ãƒ¼ã‚¿ã®ä½œæˆ
            result_data = {
                'generated_text': generated_text,
                'output_path': output_path,
                'content_type': content_type
            }
            result_data.update(additional_results)
            
            return ProcessingResult(
                success=True,
                data=result_data,
                error=None,
                metadata={
                    'function_name': function_name,
                    'processing_time': duration,
                    'content_type': content_type,
                    'timestamp': datetime.now().isoformat()
                }
            )
            
        except Exception as e:
            return self._handle_error(e, function_name, {
                'content_type': content_type,
                'sis_summary': sis_data.get('summary', 'N/A')[:100] if isinstance(sis_data, dict) else 'Invalid SIS'
            })
    
    def _normalize_sis_data(self, sis_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        SIS ãƒ‡ãƒ¼ã‚¿ã®æ­£è¦åŒ–
        - semantics ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒã‚ã‚‹å ´åˆã¯ã€ãã®ä¸­èº«ã‚’ãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ã«å±•é–‹
        - scene_id, sis_type, summary ãªã©ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã¯ä¿æŒ
        """
        if not isinstance(sis_data, dict):
            return sis_data
        
        # semantics ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒå­˜åœ¨ã™ã‚‹å ´åˆ
        if 'semantics' in sis_data and isinstance(sis_data['semantics'], dict):
            self.logger.logger.info("ğŸ”„ Normalizing SIS data: extracting 'semantics' field to top level")
            
            # semantics ã®ä¸­èº«ã‚’å–ã‚Šå‡ºã™
            semantics = sis_data['semantics']
            
            # æ–°ã—ã„æ­£è¦åŒ–ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
            normalized = {
                'common': semantics.get('common', {}),
                'text': semantics.get('text', {}),
                'visual': semantics.get('visual', {}),
                'audio': semantics.get('audio', {})
            }
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¿æŒï¼ˆã‚ã‚Œã°ï¼‰
            if 'scene_id' in sis_data:
                normalized['scene_id'] = sis_data['scene_id']
            if 'sis_type' in sis_data:
                normalized['sis_type'] = sis_data['sis_type']
            if 'summary' in sis_data:
                normalized['summary'] = sis_data['summary']
            
            return normalized
        
        # semantics ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒãªã„å ´åˆã¯ãã®ã¾ã¾è¿”ã™
        return sis_data
    
    def _validate_sis_data(self, sis_data: Dict[str, Any]) -> None:
        """SIS ãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼"""
        if not isinstance(sis_data, dict):
            raise ValidationError('SIS data must be a dictionary')
        
        # åŸºæœ¬çš„ãªãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®å­˜åœ¨ç¢ºèªï¼ˆå³å¯†ãªæ¤œè¨¼ã¯ç·©å’Œï¼‰
        if not sis_data:
            raise ValidationError('SIS data is empty')
        
        # æœ€ä½é™å¿…è¦ãªãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ç¢ºèªï¼ˆSceneSIS_semantics.jsonå½¢å¼ï¼‰
        essential_fields = ['common']
        missing_essential = [field for field in essential_fields if field not in sis_data or not sis_data[field]]
        
        if missing_essential:
            raise ValidationError(
                f'Missing essential SIS fields: {missing_essential}',
                error_code='INCOMPLETE_SIS_DATA'
            )
        
        # æ¬ æãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’è­¦å‘Šã¨ã—ã¦è¨˜éŒ²ï¼ˆã‚¨ãƒ©ãƒ¼ã«ã—ãªã„ï¼‰
        expected_fields = ['common', 'text', 'visual', 'audio']
        missing_fields = [field for field in expected_fields if field not in sis_data]
        
        if missing_fields:
            self.logger.logger.warning(f"âš ï¸ SIS missing optional fields: {missing_fields}")
            # æ¬ æãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¨­å®š
            for field in missing_fields:
                if field == 'common':
                    sis_data[field] = {'mood': '', 'characters': [], 'location': '', 'time': '', 'weather': '', 'objects': [], 'descriptions': []}
                elif field == 'text':
                    sis_data[field] = {'style': '', 'language': 'English', 'tone': '', 'point_of_view': 'third'}
                elif field == 'visual':
                    sis_data[field] = {'style': '', 'composition': '', 'lighting': '', 'perspective': ''}
                elif field == 'audio':
                    sis_data[field] = {'genre': '', 'tempo': '', 'instruments': []}
    
    def _create_prompt(self, sis_data: Dict[str, Any], content_type: str, **kwargs) -> str:
        """ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ"""
        if content_type == "image":
            return self._create_image_prompt(
                sis_data, 
                kwargs.get('width', self.generation_config.image_width),
                kwargs.get('height', self.generation_config.image_height)
            )
        elif content_type == "music":
            return self._create_music_prompt(
                sis_data, 
                kwargs.get('duration', self.generation_config.music_duration)
            )
        elif content_type == "text":
            return self._create_text_prompt(
                sis_data, 
                kwargs.get('word_count', self.generation_config.text_word_count)
            )
        else:
            raise ContentTypeError(content_type, ['image', 'music', 'text'])
    
    def _create_image_prompt(self, sis_data: Dict[str, Any], width: int, height: int) -> str:
        """ç”»åƒç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ"""
        sis_json = json.dumps(sis_data, indent=2, ensure_ascii=False)

        return _load_prompt_template('sis2content_image_prompt.md').substitute(
            width=width,
            height=height,
            sis_json=sis_json
        )
    
    def _create_music_prompt(self, sis_data: Dict[str, Any], duration: int) -> str:
        """éŸ³æ¥½ç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆï¼ˆç”»åƒã¨åŒã˜ã‚·ãƒ³ãƒ—ãƒ«ãªæ§‹é€ ï¼‰"""
        sis_json = json.dumps(sis_data, indent=2, ensure_ascii=False)

        return _load_prompt_template('sis2content_music_prompt.md').substitute(
            duration=duration,
            sis_json=sis_json
        )
    
    def _create_fallback_music_prompt(self, sis_data: Dict[str, Any], duration: int) -> str:
        """LLMå¤±æ•—æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã§éŸ³æ¥½ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ"""
        self.logger.logger.info("ğŸ”§ Using fallback rule-based music prompt generation")
        
        prompt_parts = []
        
        # SceneSISå½¢å¼ã‹ã‚‰æƒ…å ±æŠ½å‡º
        common = sis_data.get('common', {})
        audio = sis_data.get('audio', {})
        
        # ã‚¸ãƒ£ãƒ³ãƒ«
        genre = audio.get('genre', 'ambient')
        if genre:
            prompt_parts.append(genre)
        
        # ãƒ†ãƒ³ãƒ
        tempo = audio.get('tempo', 'moderate')
        if tempo:
            prompt_parts.append(f"{tempo} tempo")
        
        # æ¥½å™¨
        instruments = audio.get('instruments', [])
        if instruments:
            inst_str = ', '.join(instruments[:2])  # æœ€å¤§2æ¥½å™¨
            prompt_parts.append(inst_str)
        
        # ãƒ ãƒ¼ãƒ‰
        mood = common.get('mood', '')
        if mood:
            prompt_parts.append(f"{mood} atmosphere")
        
        if not prompt_parts:
            return "ambient music"
        
        return ', '.join(prompt_parts)
    
    def _create_text_prompt(self, sis_data: Dict[str, Any], word_count: int) -> str:
        """ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ"""
        sis_json = json.dumps(sis_data, indent=2, ensure_ascii=False)

        return _load_prompt_template('sis2content_text_prompt.md').substitute(
            word_count=word_count,
            sis_json=sis_json
        )
    
    def _generate_with_unsloth(self, prompt: str, content_type: str) -> str:
        """Unslothã‚µãƒ¼ãƒãƒ¼ã§ã®ç”Ÿæˆ"""
        # ã‚µãƒ¼ãƒãƒ¼çŠ¶æ…‹ç¢ºèª
        self._check_unsloth_server()
        
        payload = {
            "messages": [
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt}
                    ]
                }
            ],
            "generation_options": {
                "max_new_tokens": self.generation_config.max_tokens,
                "temperature": self.generation_config.temperature,
                "cache_implementation": "static"
            }
        }
        
        try:
            response = requests.post(
                f"{self.api_config.unsloth_uri}/generate",
                json=payload,
                headers={'Content-Type': 'application/json'},
                timeout=self.api_config.timeout
            )
            
            if response.status_code == 200:
                result = response.json()
                if result.get('success') and result.get('generated_text'):
                    return self._clean_generated_text(result['generated_text'])
                else:
                    raise GeNarrativeError(result.get('error', 'No generated text in response'))
            else:
                raise GeNarrativeError(f'HTTP {response.status_code}: {response.text}')
                
        except requests.exceptions.Timeout:
            raise GeNarrativeError(f'Request timeout ({self.api_config.timeout} seconds)')

    def _generate_with_ollama(self, prompt: str) -> str:
        """Ollamaã‚µãƒ¼ãƒãƒ¼ã§ã®ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ"""
        base = self.api_config.ollama_uri
        model = self.api_config.ollama_model
        payload = {
            'model': model,
            'prompt': prompt,
            'stream': False,
            'options': {
                'temperature': float(self.generation_config.temperature),
                'num_predict': int(self.generation_config.max_tokens)
            }
        }
        try:
            resp = requests.post(f"{base}/api/generate", json=payload, timeout=(10, self.api_config.timeout))
            if resp.status_code != 200:
                raise GeNarrativeError(f"HTTP {resp.status_code} from Ollama: {resp.text[:200]}")
            rj = resp.json() or {}
            text = (rj.get('response') or '').strip()
            if not text:
                raise GeNarrativeError('Empty response from Ollama')
            return self._clean_generated_text(text)
        except requests.exceptions.Timeout:
            raise GeNarrativeError(f'Ollama request timeout ({self.api_config.timeout} seconds)')
        except requests.exceptions.ConnectionError as e:
            raise ServerConnectionError("Ollama", base) from e
    
    def _check_unsloth_server(self) -> None:
        """Unslothã‚µãƒ¼ãƒãƒ¼çŠ¶æ…‹ç¢ºèª"""
        try:
            response = requests.get(f"{self.api_config.unsloth_uri}/health", timeout=10)
            if response.status_code != 200:
                raise ServerConnectionError("Unsloth", self.api_config.unsloth_uri)
            
            health_data = response.json()
            if not health_data.get('model_loaded', False):
                raise ModelNotLoadedError(self.api_config.model_name)
                
        except requests.exceptions.ConnectionError:
            raise ServerConnectionError("Unsloth", self.api_config.unsloth_uri)
    
    def _is_unsloth_available(self) -> bool:
        """Unslothã‚µãƒ¼ãƒãƒ¼ãŒåˆ©ç”¨å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯ï¼ˆã‚¨ãƒ©ãƒ¼ã‚’æŠ•ã’ãªã„ç‰ˆï¼‰"""
        try:
            response = requests.get(f"{self.api_config.unsloth_uri}/health", timeout=5)
            if response.status_code != 200:
                return False
            
            health_data = response.json()
            return health_data.get('model_loaded', False)
                
        except Exception:
            return False
    
    def _generate_image_directly(self, sis_data: Dict[str, Any], **kwargs) -> ProcessingResult:
        """Unslothç„¡ã—ã§ç›´æ¥SDã‚µãƒ¼ãƒãƒ¼ã‚’ä½¿ç”¨ã—ãŸç”»åƒç”Ÿæˆ"""
        function_name = 'generate_image_directly'
        
        try:
            self.logger.logger.info("ğŸ–¼ï¸ Starting direct SD image generation")
            
            # SISãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç›´æ¥ç”»åƒãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ
            image_prompt = self._create_direct_image_prompt(sis_data)
            self.logger.logger.info(f"ğŸ¨ Generated prompt: {image_prompt[:100]}...")
            
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
            output_path = self._save_generated_content(
                image_prompt, 'image', **kwargs
            )
            self.logger.logger.info(f"ğŸ“ Prompt saved to: {output_path}")
            
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ã¿ã®è¦æ±‚ãªã‚‰ã€SDç”Ÿæˆã¯ã‚¹ã‚­ãƒƒãƒ—
            if kwargs.get('skip_actual_generation'):
                self.logger.logger.info("â­ï¸ Skipping SD image generation (prompt-only mode)")
                image_result = {}
            else:
                # SDã‚µãƒ¼ãƒãƒ¼ã§ç”»åƒç”Ÿæˆ
                self.logger.logger.info("ğŸ–¥ï¸ Starting SD server image generation...")
                image_result = self._generate_image_with_sd(
                    image_prompt, 
                    kwargs.get('width', self.generation_config.image_width),
                    kwargs.get('height', self.generation_config.image_height),
                    **kwargs
                )
            
            if image_result.get('success'):
                self.logger.logger.info(f"âœ… Image generation successful: {image_result.get('image_filename')}")
            else:
                self.logger.logger.warning(f"âš ï¸ Image generation failed: {image_result.get('error')}")
            
            # å‡¦ç†çµ‚äº†
            duration = self._end_processing(function_name, True)
            
            # çµæœãƒ‡ãƒ¼ã‚¿ã®ä½œæˆ
            result_data = {
                'generated_text': image_prompt,
                'output_path': output_path,
                'content_type': 'image',
                # ç”»åƒç”Ÿæˆã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ãŸå ´åˆã¯ image_result ã‚’å«ã‚ãªã„
                **({} if kwargs.get('skip_actual_generation') else {'image_result': image_result})
            }
            
            return ProcessingResult(
                success=True,
                data=result_data,
                error=None,
                metadata={
                    'function_name': function_name,
                    'processing_time': duration,
                    'content_type': 'image',
                    'method': 'prompt_only' if kwargs.get('skip_actual_generation') else 'direct_sd_generation',
                    'timestamp': datetime.now().isoformat()
                }
            )
            
        except Exception as e:
            self.logger.logger.error(f"âŒ Direct image generation failed: {str(e)}")
            return self._handle_error(e, function_name, {
                'sis_summary': sis_data.get('summary', 'N/A')[:100] if isinstance(sis_data, dict) else 'Invalid SIS'
            })
    
    def _create_direct_image_prompt(self, sis_data: Dict[str, Any]) -> str:
        """SISãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç›´æ¥ç”»åƒãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆï¼ˆLLMã‚’ä½¿ç”¨ï¼‰"""
        self.logger.logger.info("ğŸ¨ Creating image prompt from SIS data using LLM")
        
        # SceneSISå½¢å¼ã®SISãƒ‡ãƒ¼ã‚¿ã‚’JSONæ–‡å­—åˆ—åŒ–
        sis_json_str = json.dumps(sis_data, ensure_ascii=False, indent=2)
        self.logger.logger.info(f"ğŸ“Š SIS data size: {len(sis_json_str)} chars")
        
        # LLMã«æ¸¡ã™ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        system_prompt = _load_prompt_template('sis2content_direct_image_system.md').substitute()
        user_prompt = _load_prompt_template('sis2content_direct_image_user.md').substitute(
            sis_json=sis_json_str
        )
        
        try:
            # Ollamaã§ç”»åƒãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ
            self.logger.logger.info("ğŸ¤– Calling Ollama to generate image prompt...")
            payload = {
                'model': self.api_config.ollama_model,
                'messages': [
                    {'role': 'system', 'content': system_prompt},
                    {'role': 'user', 'content': user_prompt}
                ],
                'stream': False,
                'options': {
                    'temperature': 0.3,  # å‰µé€ çš„ã ãŒä¸€è²«æ€§ã‚’ä¿ã¤
                    'num_predict': 150   # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯çŸ­ã‚ã«
                }
            }
            
            response = requests.post(
                f"{self.api_config.ollama_uri}/api/chat",
                json=payload,
                timeout=60
            )
            
            if response.status_code == 200:
                result = response.json()
                message = result.get('message', {})
                generated_prompt = message.get('content', '').strip()
                
                if generated_prompt:
                    # ä¸è¦ãªå¼•ç”¨ç¬¦ã‚„ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã‚’é™¤å»
                    generated_prompt = generated_prompt.strip('"\'`')
                    if generated_prompt.startswith('```'):
                        lines = generated_prompt.split('\n')
                        generated_prompt = '\n'.join([l for l in lines if not l.startswith('```')]).strip()
                    
                    # å“è³ªã‚¿ã‚°ã‚’è¿½åŠ 
                    if 'high quality' not in generated_prompt.lower():
                        generated_prompt += ', high quality, detailed, masterpiece'
                    
                    self.logger.logger.info(f"âœ… Generated prompt ({len(generated_prompt)} chars): {generated_prompt[:100]}...")
                    return generated_prompt
                else:
                    raise GeNarrativeError('Empty response from LLM')
            else:
                raise GeNarrativeError(f'HTTP {response.status_code}: {response.text}')
                
        except Exception as e:
            self.logger.logger.warning(f"âš ï¸ LLM prompt generation failed: {str(e)}, falling back to rule-based")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã®ç°¡æ˜“ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
            return self._create_fallback_image_prompt(sis_data)
    
    def _create_fallback_image_prompt(self, sis_data: Dict[str, Any]) -> str:
        """LLMå¤±æ•—æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ"""
        self.logger.logger.info("ğŸ”§ Using fallback rule-based prompt generation")
        
        prompt_parts = []
        
        # SceneSISå½¢å¼ã‹ã‚‰æƒ…å ±æŠ½å‡º
        common = sis_data.get('common', {})
        visual = sis_data.get('visual', {})
        
        # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼
        characters = common.get('characters', [])
        for char in characters[:2]:  # æœ€å¤§2ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼
            if isinstance(char, dict):
                name = char.get('name', '')
                traits = ', '.join(char.get('traits', [])[:3])
                visual_info = char.get('visual', {})
                hair = visual_info.get('hair', '')
                clothes = visual_info.get('clothes', '')
                parts = [p for p in [name, traits, hair, clothes] if p]
                if parts:
                    prompt_parts.append(' '.join(parts))
        
        # å ´æ‰€ãƒ»æ™‚é–“ãƒ»å¤©æ°—
        location = common.get('location', '')
        time = common.get('time', '')
        weather = common.get('weather', '')
        scene_parts = [p for p in [location, time, weather] if p]
        if scene_parts:
            prompt_parts.append(', '.join(scene_parts))
        
        # ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        objects = common.get('objects', [])
        for obj in objects[:3]:  # æœ€å¤§3ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
            if isinstance(obj, dict):
                obj_name = obj.get('name', '')
                obj_colors = ', '.join(obj.get('colors', []))
                if obj_name:
                    prompt_parts.append(f"{obj_colors} {obj_name}" if obj_colors else obj_name)
        
        # èª¬æ˜
        descriptions = common.get('descriptions', [])
        if descriptions:
            prompt_parts.append(descriptions[0])
        
        # ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã‚¹ã‚¿ã‚¤ãƒ«
        style = visual.get('style', '')
        lighting = visual.get('lighting', '')
        composition = visual.get('composition', '')
        visual_parts = [p for p in [lighting, style, composition] if p]
        if visual_parts:
            prompt_parts.append(', '.join(visual_parts))
        
        # ãƒ ãƒ¼ãƒ‰
        mood = common.get('mood', '')
        if mood:
            prompt_parts.append(f"{mood} atmosphere")
        
        base_prompt = ', '.join(prompt_parts)
        return f"{base_prompt}, high quality, detailed, masterpiece"
    
    def _clean_generated_text(self, generated_text: str) -> str:
        """ç”Ÿæˆãƒ†ã‚­ã‚¹ãƒˆã®ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°"""
        clean_text = generated_text.strip()
        
        # LLMãƒˆãƒ¼ã‚¯ãƒ³ã®é™¤å»
        llm_tokens = [
            '<bos>', '<eos>', '<pad>', '<unk>',
            '<start_of_turn>', '<end_of_turn>',
            '<start_of_turn>model', '<start_of_turn>user', '<start_of_turn>assistant',
        ]
        
        for token in llm_tokens:
            clean_text = clean_text.replace(token, '')
        
        # ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã®é™¤å»
        if '```' in clean_text:
            clean_text = re.sub(r'```[^`]*```', '', clean_text)
        
        # ãƒ¢ãƒ‡ãƒ«ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®æŠ½å‡º
        if '<start_of_turn>model' in clean_text:
            clean_text = clean_text.split('<start_of_turn>model')[-1]
            clean_text = clean_text.replace('<end_of_turn>', '')
        
        return clean_text.strip()
    
    def _save_generated_content(self, generated_text: str, content_type: str, **kwargs) -> str:
        """ç”Ÿæˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ä¿å­˜"""
        # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®æ±ºå®š
        custom_timestamp = kwargs.get('custom_timestamp')
        if custom_timestamp:
            timestamp = custom_timestamp
            test_dir = f"{self.processing_config.output_dir}/test_result_{timestamp}"
        else:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            test_dir = f"{self.processing_config.output_dir}/test_result_{timestamp}"
        
        # ãƒ•ã‚¡ã‚¤ãƒ«åã®æ±ºå®š
        test_case_name = kwargs.get('test_case_name', '')
        prefix = f"{test_case_name}_" if test_case_name else ""
        
        if content_type == "text":
            filename = f"{prefix}sis2story.txt"
        elif content_type == "image":
            filename = f"{prefix}sis2image_prompt.txt"
        elif content_type == "music":
            filename = f"{prefix}sis2music_prompt.txt"
        else:
            filename = f"{prefix}sis_{content_type}.txt"
        
        output_path = f"{test_dir}/{filename}"
        os.makedirs(test_dir, exist_ok=True)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(generated_text)
        
        return output_path
    
    def _generate_additional_content(self, generated_text: str, content_type: str, **kwargs) -> Dict[str, Any]:
        """è¿½åŠ ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç”Ÿæˆï¼ˆç”»åƒãƒ»éŸ³æ¥½ï¼‰"""
        additional_results = {}
        
        if content_type == "image":
            # Stable Diffusion ã§ã®ç”»åƒç”Ÿæˆ
            if self._check_sd_server():
                self.logger.logger.info("ğŸ–¼ï¸ Generating actual image...")
                image_result = self._generate_image_with_sd(
                    generated_text, 
                    kwargs.get('width', self.generation_config.image_width),
                    kwargs.get('height', self.generation_config.image_height),
                    **kwargs
                )
                additional_results['image_result'] = image_result
            else:
                self.logger.logger.warning("âš ï¸ SD server not available, skipping image generation")
        
        elif content_type == "music":
            # Music server ã§ã®éŸ³æ¥½ç”Ÿæˆ
            if self._check_music_server():
                self.logger.logger.info("ğŸµ Generating actual music...")
                music_result = self._generate_music_with_server(
                    generated_text,
                    kwargs.get('duration', self.generation_config.music_duration),
                    **kwargs
                )
                additional_results['music_result'] = music_result
            else:
                self.logger.logger.warning("âš ï¸ Music server not available, skipping music generation")
        
        return additional_results
    
    def _check_sd_server(self) -> bool:
        """Stable Diffusion ã‚µãƒ¼ãƒãƒ¼ç¢ºèª"""
        try:
            self.logger.logger.info(f"ğŸ” Checking SD server at: {self.api_config.sd_uri}")
            response = requests.get(f"{self.api_config.sd_uri}/sdapi/v1/memory", timeout=10)
            
            if response.status_code == 200:
                memory_info = response.json()
                self.logger.logger.info(f"âœ… SD server is available")
                self.logger.logger.info(f"ğŸ’¾ Memory info: {memory_info.get('ram', {})}")
                return True
            else:
                self.logger.logger.warning(f"âš ï¸ SD server returned status {response.status_code}")
                return False
                
        except requests.exceptions.ConnectionError as e:
            self.logger.logger.error(f"âŒ SD server connection error: {str(e)}")
            return False
        except requests.exceptions.Timeout as e:
            self.logger.logger.error(f"âŒ SD server timeout: {str(e)}")
            return False
        except Exception as e:
            self.logger.logger.error(f"âŒ SD server check failed: {str(e)}")
            return False
    
    def _check_music_server(self) -> bool:
        """Music ã‚µãƒ¼ãƒãƒ¼ç¢ºèª"""
        try:
            response = requests.get(f"{self.api_config.music_uri}/health", timeout=10)
            return response.status_code == 200
        except Exception:
            return False
    
    def _check_tts_server(self) -> bool:
        """TTS ã‚µãƒ¼ãƒãƒ¼ç¢ºèª"""
        try:
            response = requests.get(f"{self.api_config.tts_uri}", timeout=10)
            return response.status_code == 200
        except Exception:
            return False
    
    def _generate_image_with_sd(self, image_prompt: str, width: int, height: int, **kwargs) -> Dict[str, Any]:
        """Stable Diffusion ã§ç”»åƒç”Ÿæˆ"""
        self.logger.logger.info(f"ğŸ–¼ï¸ Starting SD image generation {width}x{height}")
        self.logger.logger.info(f"ğŸ“ Prompt: {image_prompt[:100]}...")
        self.logger.logger.info(f"ğŸ”— SD URI: {self.api_config.sd_uri}")
        
        # ã¾ãšSDã‚µãƒ¼ãƒãƒ¼ã®å¥åº·çŠ¶æ…‹ã‚’ãƒã‚§ãƒƒã‚¯
        try:
            health_response = requests.get(f"{self.api_config.sd_uri}/sdapi/v1/memory", timeout=10)
            self.logger.logger.info(f"ğŸ¥ SD health check: {health_response.status_code}")
            if health_response.status_code == 200:
                memory_info = health_response.json()
                self.logger.logger.info(f"ğŸ’¾ SD memory info: {memory_info.get('ram', {}).get('used', 'unknown')}")
            else:
                self.logger.logger.warning(f"âš ï¸ SD health check failed: {health_response.status_code}")
        except Exception as health_error:
            self.logger.logger.warning(f"âš ï¸ SD health check error: {str(health_error)}")
        
        generation_params = {
            "prompt": image_prompt,
            "negative_prompt": "low quality, blurry, distorted, ugly, bad anatomy, text, watermark",
            "width": width,
            "height": height,
            "steps": 25,
            "cfg_scale": 7.5,
            "sampler_name": "DPM++ 2M Karras",
            "batch_size": 1,
            "n_iter": 1,
            "seed": -1,
        }
        
        self.logger.logger.info(f"ğŸ”§ Generation params: steps={generation_params['steps']}, cfg_scale={generation_params['cfg_scale']}, sampler={generation_params['sampler_name']}")
        self.logger.logger.info(f"ğŸ“ Image dimensions: {width}x{height}")
        
        start_time = time.time()
        
        try:
            self.logger.logger.info(f"ğŸ“¡ Sending POST request to {self.api_config.sd_uri}/sdapi/v1/txt2img")
            self.logger.logger.info(f"ğŸ“¦ Request payload size: {len(str(generation_params))} chars")
            
            response = requests.post(
                f"{self.api_config.sd_uri}/sdapi/v1/txt2img",
                json=generation_params,
                headers={'Content-Type': 'application/json'},
                timeout=120
            )
            
            generation_time = time.time() - start_time
            self.logger.logger.info(f"â±ï¸ SD request completed in {generation_time:.1f} seconds")
            self.logger.logger.info(f"ğŸ“Š Response status: {response.status_code}")
            self.logger.logger.info(f"ğŸ“Š Response headers: {dict(response.headers)}")
            
            if response.status_code == 200:
                try:
                    result = response.json()
                    self.logger.logger.info(f"âœ… JSON response parsed successfully")
                    self.logger.logger.info(f"ğŸ”‘ Response keys: {list(result.keys())}")
                    
                    if 'images' in result and result['images']:
                        img_base64 = result['images'][0]
                        self.logger.logger.info(f"ğŸ–¼ï¸ Base64 image data length: {len(img_base64)} chars")
                        
                        try:
                            img_bytes = base64.b64decode(img_base64)
                            self.logger.logger.info(f"âœ… Base64 decode successful, image size: {len(img_bytes)} bytes")
                            
                            # ç”»åƒã®ä¿å­˜
                            image_path = self._save_generated_image(img_bytes, **kwargs)
                            self.logger.logger.info(f"âœ… Image saved successfully to: {image_path}")
                            
                            return {
                                'success': True,
                                'image_path': image_path,
                                'image_filename': os.path.basename(image_path),
                                'image_size': len(img_bytes),
                                'generation_time': generation_time,
                                'prompt': image_prompt,
                                'parameters': generation_params
                            }
                        except Exception as decode_error:
                            error_msg = f'Base64 decode error: {str(decode_error)}'
                            self.logger.logger.error(f"âŒ {error_msg}")
                            return {'success': False, 'error': error_msg}
                    else:
                        error_msg = f'No images in response from SD server. Response: {result}'
                        self.logger.logger.error(f"âŒ {error_msg}")
                        return {'success': False, 'error': error_msg}
                
                except json.JSONDecodeError as json_error:
                    error_msg = f'JSON decode error: {str(json_error)}. Raw response: {response.text[:500]}'
                    self.logger.logger.error(f"âŒ {error_msg}")
                    return {'success': False, 'error': error_msg}
            else:
                error_msg = f'HTTP {response.status_code}: {response.text[:500]}'
                self.logger.logger.error(f"âŒ SD server error: {error_msg}")
                return {'success': False, 'error': error_msg}
                
        except requests.exceptions.Timeout:
            error_msg = f'Image generation timed out after {120} seconds'
            self.logger.logger.error(f"âŒ {error_msg}")
            return {'success': False, 'error': error_msg}
        except requests.exceptions.ConnectionError as conn_error:
            error_msg = f'Connection error to SD server: {str(conn_error)}'
            self.logger.logger.error(f"âŒ {error_msg}")
            return {'success': False, 'error': error_msg}
        except Exception as e:
            error_msg = f'Unexpected image generation error: {str(e)}'
            self.logger.logger.error(f"âŒ {error_msg}")
            import traceback
            self.logger.logger.error(f"ğŸ“ Traceback: {traceback.format_exc()}")
            return {'success': False, 'error': error_msg}
    
    def _generate_music_with_server(self, music_prompt: str, duration: int, **kwargs) -> Dict[str, Any]:
        """Music server ã§éŸ³æ¥½ç”Ÿæˆ"""
        payload = {
            "prompt": music_prompt,
            "duration": duration,
            "temperature": 0.8
        }
        
        start_time = time.time()
        
        try:
            response = requests.post(
                f"{self.api_config.music_uri}/generate",
                json=payload,
                timeout=max(120, duration * 3)
            )
            
            if response.status_code == 200:
                result = response.json()
                generation_time = time.time() - start_time
                
                if 'filename' in result:
                    original_music_path = f"/app/shared/{result['filename']}"
                    
                    if os.path.exists(original_music_path):
                        # éŸ³æ¥½ãƒ•ã‚¡ã‚¤ãƒ«ã®ç§»å‹•
                        music_path = self._save_generated_music(original_music_path, **kwargs)
                        music_size = os.path.getsize(music_path)
                        
                        return {
                            'success': True,
                            'music_path': music_path,
                            'music_filename': os.path.basename(music_path),
                            'music_size': music_size,
                            'sample_rate': result.get('sample_rate', 32000),
                            'generation_time': generation_time
                        }
                    else:
                        return {'success': False, 'error': f'Generated file not found: {original_music_path}'}
                else:
                    return {'success': False, 'error': 'No filename in response'}
            else:
                return {'success': False, 'error': f'HTTP {response.status_code}'}
                
        except requests.exceptions.Timeout:
            timeout_duration = max(120, duration * 3)
            return {'success': False, 'error': f'Music generation timed out ({timeout_duration} seconds)'}
        except Exception as e:
            return {'success': False, 'error': str(e)}
    
    def _save_generated_image(self, img_bytes: bytes, **kwargs) -> str:
        """ç”Ÿæˆç”»åƒã®ä¿å­˜"""
        # ä¿å­˜å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®æ±ºå®š
        custom_timestamp = kwargs.get('custom_timestamp')
        if custom_timestamp:
            test_dir = f"{self.processing_config.output_dir}/test_result_{custom_timestamp}"
        else:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            test_dir = f"{self.processing_config.output_dir}/test_result_{timestamp}"
        
        # ãƒ•ã‚¡ã‚¤ãƒ«åã®æ±ºå®š
        test_case_name = kwargs.get('test_case_name', '')
        prefix = f"{test_case_name}_" if test_case_name else ""
        image_path = f"{test_dir}/{prefix}generated_image.png"
        
        self.logger.logger.info(f"ğŸ’¾ Saving image to: {image_path}")
        self.logger.logger.info(f"ğŸ“Š Image data size: {len(img_bytes)} bytes")
        self.logger.logger.info(f"ğŸ“ Target directory: {test_dir}")
        
        try:
            # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
            os.makedirs(test_dir, exist_ok=True)
            self.logger.logger.info(f"âœ… Directory created/confirmed: {test_dir}")
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
            with open(image_path, "wb") as f:
                f.write(img_bytes)
            
            # ä¿å­˜ç¢ºèª
            if os.path.exists(image_path):
                saved_size = os.path.getsize(image_path)
                self.logger.logger.info(f"âœ… Image saved successfully: {saved_size} bytes")
                self.logger.logger.info(f"ğŸ“ Final path: {image_path}")
            else:
                self.logger.logger.error(f"âŒ Image file not found after save attempt")
                
        except Exception as save_error:
            self.logger.logger.error(f"âŒ Error saving image: {str(save_error)}")
            raise
        
        return image_path
    
    def _save_generated_music(self, original_music_path: str, **kwargs) -> str:
        """ç”ŸæˆéŸ³æ¥½ã®ä¿å­˜"""
        # ä¿å­˜å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®æ±ºå®š
        custom_timestamp = kwargs.get('custom_timestamp')
        if custom_timestamp:
            test_dir = f"{self.processing_config.output_dir}/test_result_{custom_timestamp}"
        else:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            test_dir = f"{self.processing_config.output_dir}/test_result_{timestamp}"
        
        # ãƒ•ã‚¡ã‚¤ãƒ«åã®æ±ºå®š
        test_case_name = kwargs.get('test_case_name', '')
        prefix = f"{test_case_name}_" if test_case_name else ""
        music_path = f"{test_dir}/{prefix}generated_music.wav"
        
        # ç§»å‹•
        os.makedirs(test_dir, exist_ok=True)
        shutil.move(original_music_path, music_path)
        
        return music_path


    def text2speech(self, text: str, **kwargs) -> Dict[str, Any]:
        """
        ãƒ†ã‚­ã‚¹ãƒˆã‚’éŸ³å£°ã«å¤‰æ›ã™ã‚‹é–¢æ•°
        
        Args:
            text: éŸ³å£°ã«å¤‰æ›ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆï¼ˆè‹±èªå‰æï¼‰
            **kwargs: è¿½åŠ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
                - custom_timestamp: ã‚«ã‚¹ã‚¿ãƒ ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
                - test_case_name: ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹å
                - output_filename: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆæ‹¡å¼µå­ãªã—ï¼‰
        
        Returns:
            éŸ³å£°ç”Ÿæˆçµæœã®è¾æ›¸
        """
        self.logger.logger.info(f"ğŸ¤ Starting text-to-speech conversion")
        self.logger.logger.info(f"ğŸ“ Text: {text[:100]}{'...' if len(text) > 100 else ''}")
        
        # TTSã‚µãƒ¼ãƒãƒ¼ç¢ºèª
        if not self._check_tts_server():
            return {
                'success': False,
                'error': 'TTS server is not available',
                'audio_path': None
            }
        
        start_time = time.time()
        
        try:
            # TTSã‚µãƒ¼ãƒãƒ¼ã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡
            params = {"text": text}
            response = requests.get(
                f"{self.api_config.tts_uri}/api/tts",
                params=params,
                timeout=60
            )
            
            if response.status_code == 200:
                generation_time = time.time() - start_time
                
                # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿å­˜
                audio_path = self._save_generated_audio(response.content, **kwargs)
                audio_size = len(response.content)
                
                self.logger.logger.info(f"âœ… TTS generation successful")
                self.logger.logger.info(f"ğŸ“ Audio saved to: {audio_path}")
                self.logger.logger.info(f"â±ï¸ Generation time: {generation_time:.1f} seconds")
                self.logger.logger.info(f"ğŸ“Š File size: {audio_size / 1024:.1f}KB")
                
                return {
                    'success': True,
                    'audio_path': audio_path,
                    'audio_filename': os.path.basename(audio_path),
                    'audio_size': audio_size,
                    'generation_time': generation_time,
                    'text_length': len(text),
                    'error': None
                }
            else:
                error_msg = f'HTTP {response.status_code}: {response.text[:200]}'
                self.logger.logger.error(f"âŒ TTS request failed: {error_msg}")
                return {
                    'success': False,
                    'error': error_msg,
                    'audio_path': None
                }
                
        except requests.exceptions.Timeout:
            error_msg = 'TTS request timeout (60 seconds)'
            self.logger.logger.error(f"âŒ {error_msg}")
            return {
                'success': False,
                'error': error_msg,
                'audio_path': None
            }
        except Exception as e:
            error_msg = f'TTS generation error: {str(e)}'
            self.logger.logger.error(f"âŒ {error_msg}")
            return {
                'success': False,
                'error': error_msg,
                'audio_path': None
            }
    
    def _save_generated_audio(self, audio_bytes: bytes, **kwargs) -> str:
        """ç”ŸæˆéŸ³å£°ã®ä¿å­˜"""
        # ä¿å­˜å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®æ±ºå®š
        custom_timestamp = kwargs.get('custom_timestamp')
        if custom_timestamp:
            test_dir = f"{self.processing_config.output_dir}/test_result_{custom_timestamp}"
        else:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            test_dir = f"{self.processing_config.output_dir}/test_result_{timestamp}"
        
        # ãƒ•ã‚¡ã‚¤ãƒ«åã®æ±ºå®š
        test_case_name = kwargs.get('test_case_name', '')
        output_filename = kwargs.get('output_filename', 'generated_speech')
        
        prefix = f"{test_case_name}_" if test_case_name else ""
        audio_path = f"{test_dir}/{prefix}{output_filename}.wav"
        
        # ä¿å­˜
        os.makedirs(test_dir, exist_ok=True)
        with open(audio_path, "wb") as f:
            f.write(audio_bytes)
        
        return audio_path


# ========================================
# çµ±ä¸€ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆé–¢æ•°
# ========================================

def generate_content(
    sis_data: Dict[str, Any],
    content_type: str,
    api_config: Optional[APIConfig] = None,
    processing_config: Optional[ProcessingConfig] = None,
    generation_config: Optional[GenerationConfig] = None,
    logger: Optional[StructuredLogger] = None,
    **kwargs
) -> Dict[str, Any]:
    """
    çµ±åˆã•ã‚ŒãŸã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç”Ÿæˆé–¢æ•°
    
    Args:
        sis_data: SISæ§‹é€ ãƒ‡ãƒ¼ã‚¿
        content_type: ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¿ã‚¤ãƒ— ('image' | 'music' | 'text')
        api_config: APIè¨­å®š
        processing_config: å‡¦ç†è¨­å®š
        generation_config: ç”Ÿæˆè¨­å®š
        logger: ãƒ­ã‚¬ãƒ¼
        **kwargs: è¿½åŠ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    
    Returns:
        çµ±ä¸€ã•ã‚ŒãŸæˆ»ã‚Šå€¤è¾æ›¸
    """
    generator = ContentGenerator(api_config, processing_config, generation_config, logger)
    result = generator.process(sis_data, content_type, **kwargs)
    return result.to_dict()


# ========================================
# æ—¢å­˜é–¢æ•°ï¼ˆå¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ï¼‰
# ========================================

def generate_content_with_unsloth(
    sis_data: Dict[str, Any], 
    api_uri: str, 
    content_type: str, 
    **kwargs
) -> Dict[str, Any]:
    """
    æ—¢å­˜é–¢æ•°åã§ã®äº’æ›æ€§é–¢æ•°
    """
    api_config = APIConfig(unsloth_uri=api_uri)
    return generate_content(sis_data, content_type, api_config, **kwargs)


def load_sis_data(sis_file_path: str) -> Optional[Dict[str, Any]]:
    """SIS ãƒ‡ãƒ¼ã‚¿ã®ãƒ­ãƒ¼ãƒ‰"""
    try:
        with open(sis_file_path, 'r', encoding='utf-8') as f:
            sis_data = json.load(f)
        print(f"âœ… SIS data loaded from: {sis_file_path}")
        return sis_data
    except FileNotFoundError:
        print(f"âŒ SIS file not found: {sis_file_path}")
        return None
    except json.JSONDecodeError as e:
        print(f"âŒ Invalid JSON in SIS file: {e}")
        return None
    except Exception as e:
        print(f"âŒ Error loading SIS file: {e}")
        return None


# ========================================
# ãƒ¡ã‚¤ãƒ³é–¢æ•°
# ========================================

def main():
    parser = argparse.ArgumentParser(description='Generate content from SIS data using unified approach')
    parser.add_argument('--mode', choices=['image', 'music', 'text', 'tts'], required=True,
                       help='Type of content to generate')
    parser.add_argument('--api_uri', default='http://unsloth:5007',
                       help='Unsloth API URI (default: http://unsloth:5007)')
    parser.add_argument('--sd_api_uri', default='http://sd:7860',
                       help='Stable Diffusion API URI (default: http://sd:7860)')
    parser.add_argument('--music_api_uri', default='http://music:5003',
                       help='Music API URI (default: http://music:5003)')
    parser.add_argument('--tts_api_uri', default='http://tts:5002',
                       help='TTS API URI (default: http://tts:5002)')
    parser.add_argument('--sis_file', default='/app/shared/sis/test_sis.json',
                       help='Path to SIS JSON file')
    
    # Image-specific arguments
    parser.add_argument('--width', type=int, default=1024,
                       help='Image width (default: 1024)')
    parser.add_argument('--height', type=int, default=768,
                       help='Image height (default: 768)')
    
    # Music-specific arguments
    parser.add_argument('--duration', type=int, default=30,
                       help='Music duration in seconds (default: 30)')
    
    # Text-specific arguments
    parser.add_argument('--word_count', type=int, default=50,
                       help='Target word count for story (default: 50)')
    
    # TTS-specific arguments
    parser.add_argument('--text_input', type=str,
                       help='Direct text input for TTS (overrides SIS-based text generation)')
    parser.add_argument('--output_filename', type=str, default='generated_speech',
                       help='Output filename for TTS audio (without extension, default: generated_speech)')
    
    parser.add_argument('--custom_timestamp', type=str,
                       help='Custom timestamp for directory naming (for batch testing)')
    parser.add_argument('--test_case_name', type=str,
                       help='Test case name prefix for file naming (for batch testing)')
    
    args = parser.parse_args()
    
    print(f"ğŸ¯ SIS to {args.mode.title()} Generation (Unified)")
    print("=" * 50)
    
    # è¨­å®šã®ä½œæˆ
    api_config = APIConfig(
        unsloth_uri=args.api_uri,
        sd_uri=args.sd_api_uri,
        music_uri=args.music_api_uri,
        tts_uri=args.tts_api_uri
    )
    
    generation_config = GenerationConfig(
        image_width=args.width,
        image_height=args.height,
        music_duration=args.duration,
        text_word_count=args.word_count
    )
    
    # SIS ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
    print(f"\nğŸ“„ Loading SIS data...")
    sis_data = load_sis_data(args.sis_file)
    if not sis_data and args.mode != 'tts':
        return False
    
    # TTSãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã€ç›´æ¥ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ãŒã‚ã‚Œã°SISãƒ‡ãƒ¼ã‚¿ã¯ä¸è¦
    if args.mode == 'tts' and args.text_input:
        sis_data = None  # SISãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã‚ãªã„
    elif not sis_data:
        return False
    
    # SIS ãƒ‡ãƒ¼ã‚¿ã®ã‚µãƒãƒªãƒ¼è¡¨ç¤ºï¼ˆSISãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã®ã¿ï¼‰
    if sis_data:
        print(f"   Summary: {sis_data.get('summary', 'N/A')}")
        print(f"   Emotions: {', '.join(sis_data.get('emotions', []))}")
        print(f"   Mood: {sis_data.get('mood', 'N/A')}")
    
    # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç”Ÿæˆ
    print(f"\nğŸ¨ Generating {args.mode}...")
    
    # TTSãƒ¢ãƒ¼ãƒ‰ã®ç‰¹åˆ¥å‡¦ç†
    if args.mode == 'tts':
        generator = ContentGenerator(api_config, generation_config=generation_config)
        
        if args.text_input:
            # ç›´æ¥ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›
            text_to_convert = args.text_input
            print(f"ğŸ“ Using direct text input: {text_to_convert[:100]}{'...' if len(text_to_convert) > 100 else ''}")
        else:
            # SISã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ
            print(f"ğŸ“ Generating text from SIS data first...")
            text_result = generator.process(sis_data, 'text', **kwargs)
            if not text_result.success:
                print(f"âŒ Text generation failed: {text_result.error}")
                return False
            text_to_convert = text_result.data['generated_text']
            print(f"ğŸ“ Generated text: {text_to_convert[:100]}{'...' if len(text_to_convert) > 100 else ''}")
        
        # TTSå¤‰æ›
        tts_kwargs = {
            'custom_timestamp': args.custom_timestamp,
            'test_case_name': args.test_case_name,
            'output_filename': args.output_filename
        }
        tts_result = generator.text2speech(text_to_convert, **tts_kwargs)
        
        if tts_result['success']:
            print(f"\nâœ… TTS generation completed!")
            print(f"ğŸ“ Audio saved to: {tts_result['audio_path']}")
            print(f"â±ï¸ Generation time: {tts_result['generation_time']:.1f} seconds")
            print(f"ğŸ“Š File size: {tts_result['audio_size'] / 1024:.1f}KB")
            print(f"ğŸ“ Text length: {tts_result['text_length']} characters")
            print(f"\nğŸµ How to play:")
            print(f"  aplay {tts_result['audio_path']}")
            return True
        else:
            print(f"\nâŒ TTS generation failed: {tts_result['error']}")
            return False
    
    # å¾“æ¥ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç”Ÿæˆå‡¦ç†
    kwargs = {
        'width': args.width,
        'height': args.height,
        'duration': args.duration,
        'word_count': args.word_count,
        'custom_timestamp': args.custom_timestamp,
        'test_case_name': args.test_case_name
    }
    
    result = generate_content(
        sis_data, 
        args.mode, 
        api_config, 
        generation_config=generation_config,
        **kwargs
    )
    
    if result['success']:
        print(f"\nâœ… {args.mode.title()} generation completed!")
        print(f"ğŸ“ Output saved to: {result['output_path']}")
        print(f"â±ï¸ Generation time: {result['metadata']['processing_time']:.1f} seconds")
        print(f"ğŸ“ Content length: {len(result['generated_text'])} characters")
        
        # è¿½åŠ ç”Ÿæˆçµæœã®è¡¨ç¤º
        if result.get('image_result'):
            img_result = result['image_result']
            if img_result['success']:
                print(f"ğŸ–¼ï¸ Image saved to: {img_result['image_path']}")
                print(f"â±ï¸ Image generation time: {img_result['generation_time']:.1f} seconds")
            else:
                print(f"âŒ Image generation failed: {img_result['error']}")
        
        if result.get('music_result'):
            music_result = result['music_result']
            if music_result['success']:
                print(f"ğŸµ Music saved to: {music_result['music_path']}")
                print(f"â±ï¸ Music generation time: {music_result['generation_time']:.1f} seconds")
                print(f"ğŸ“Š File size: {music_result['music_size'] / 1024:.1f}KB")
                print(f"ğŸ›ï¸ Sample rate: {music_result['sample_rate']} Hz")
            else:
                print(f"âŒ Music generation failed: {music_result['error']}")
        
        # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤º
        preview = result['generated_text'][:200]
        if len(result['generated_text']) > 200:
            preview += "..."
        print(f"\nğŸ“– Preview:\n{preview}")
        
        return True
    else:
        print(f"\nâŒ {args.mode.title()} generation failed: {result['error']}")
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
