#!/usr/bin/env python3
"""
Unified Content to SIS (Semantic Interface Structure) Extraction Script

çµ±ä¸€ã•ã‚ŒãŸå®Ÿè£…æ–¹é‡ã«ã‚ˆã‚‹ã€å„ç¨®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‹ã‚‰ã®SISæŠ½å‡ºæ©Ÿèƒ½
- æ—¢å­˜ã®å€‹åˆ¥é–¢æ•°ï¼ˆaudio2SIS, image2SIS, text2SISï¼‰ã‚’ç¶­æŒ
- æ–°ã—ã„çµ±åˆã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆï¼ˆextract_sis_from_contentï¼‰ã‚’è¿½åŠ 
- çµ±ä¸€ã•ã‚ŒãŸã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã¨æˆ»ã‚Šå€¤æ§‹é€ 
- è¨­å®šã‚¯ãƒ©ã‚¹ã¨ãƒ­ã‚®ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ã®çµ±åˆ

Author: Generated from GeNarrative Pipeline
Created: August 6, 2025
Updated: August 6, 2025 - Unified implementation
"""

import os
import json
import base64
import requests
import time
from datetime import datetime
from typing import Dict, Any, Optional, Tuple
from pathlib import Path
from functools import lru_cache
from string import Template

# å…±é€šåŸºç›¤ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from common_base import (
    APIConfig, ProcessingConfig, GenerationConfig,
    ContentProcessor, ProcessingResult, StructuredLogger,
    GeNarrativeError, FileProcessingError, ServerConnectionError, 
    ModelNotLoadedError, ContentTypeError, ValidationError,
    detect_content_type, create_standard_response
)


PROMPT_DIR = Path(__file__).parent / 'prompts'


@lru_cache(maxsize=16)
def _load_prompt_template(filename: str) -> Template:
    """Load and cache prompt templates stored under ui/scripts/prompts."""
    template_path = PROMPT_DIR / filename
    if not template_path.exists():
        raise FileNotFoundError(f"Prompt template not found: {template_path}")
    with open(template_path, 'r', encoding='utf-8') as prompt_file:
        return Template(prompt_file.read())


# ========================================
# SISæŠ½å‡ºãƒ—ãƒ­ã‚»ãƒƒã‚µã‚¯ãƒ©ã‚¹ï¼ˆç”¨èªä¸Šã€‚ã‚¯ãƒ©ã‚¹åã¯äº’æ›ã®ãŸã‚SISExtractorï¼‰
# ========================================

class SISExtractor(ContentProcessor):
    """çµ±ä¸€ã•ã‚ŒãŸSISæŠ½å‡ºã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, 
                 api_config: Optional[APIConfig] = None,
                 processing_config: Optional[ProcessingConfig] = None,
                 logger: Optional[StructuredLogger] = None):
        super().__init__(api_config, processing_config, logger)
    
    def process(self, content_path: str, content_type: str = None, **kwargs) -> ProcessingResult:
        """çµ±åˆSISæŠ½å‡ºå‡¦ç†ï¼ˆå‡¦ç†å†…å®¹ã¯åŒä¸€ã€ç”¨èªã‚’SISã«çµ±ä¸€ï¼‰"""
        function_name = 'extract_sis_from_content'
        
        try:
            # å‡¦ç†é–‹å§‹
            self._start_processing(function_name, {
                'content_path': content_path,
                'content_type': content_type
            })
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹æ¤œè¨¼
            self._validate_file_path(content_path)
            
            # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¿ã‚¤ãƒ—åˆ¤å®š
            if content_type is None:
                content_type = detect_content_type(content_path)
            
            if content_type == 'unknown':
                raise ContentTypeError(content_type, ['audio', 'image', 'text'])
            
            # å¯¾å¿œã™ã‚‹å‡¦ç†ã‚’å®Ÿè¡Œ
            if content_type == 'audio':
                result = self._process_audio(content_path, **kwargs)
            elif content_type == 'image':
                result = self._process_image(content_path, **kwargs)
            elif content_type == 'text':
                result = self._process_text(content_path, **kwargs)
            else:
                raise ContentTypeError(content_type, ['audio', 'image', 'text'])
            
            # å‡¦ç†çµ‚äº†
            duration = self._end_processing(function_name, result.success)
            result.metadata['processing_time'] = duration
            
            return result
            
        except Exception as e:
            return self._handle_error(e, function_name, {'content_path': content_path})
    
    def _process_audio(self, audio_path: str, **kwargs) -> ProcessingResult:
        """éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†"""
        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã®æ¤œè¨¼
        supported_formats = ['.wav', '.mp3', '.m4a', '.flac']
        file_ext = os.path.splitext(audio_path)[1].lower()
        if file_ext not in supported_formats:
            raise ValidationError(
                f'Unsupported audio format: {file_ext}. Supported: {supported_formats}',
                error_code='UNSUPPORTED_AUDIO_FORMAT'
            )
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
        file_size = os.path.getsize(audio_path)
        max_size = 50 * 1024 * 1024  # 50MB
        if file_size > max_size:
            raise ValidationError(
                f'Audio file too large: {file_size / (1024*1024):.1f}MB. Maximum: 50MB',
                error_code='FILE_TOO_LARGE'
            )
        
        # SISæŠ½å‡ºå®Ÿè¡Œ
        sis_data = self._extract_sis_from_audio(audio_path)
        
        return ProcessingResult(
            success=True,
            data={'sis_data': sis_data},
            error=None,
            metadata={
                'content_type': 'audio',
                'file_size': file_size,
                'timestamp': datetime.now().isoformat()
            }
        )
    
    def _process_image(self, image_path: str, **kwargs) -> ProcessingResult:
        """ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ï¼ˆStructured Output ã‚’ä½¿ç”¨ã€å®Œå…¨ãªSceneSISã‚¹ã‚­ãƒ¼ãƒã«æº–æ‹ ï¼‰"""
        # ç”»åƒã‚’base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
        image_base64 = self._load_and_encode_image(image_path)
        if not image_base64:
            raise ValidationError(
                'Failed to encode image to base64',
                error_code='IMAGE_ENCODING_FAILED'
            )

        # å®Œå…¨ãªSceneSISã‚¹ã‚­ãƒ¼ãƒã‚’å–å¾—
        scene_sis_schema = self._scene_sis_schema()
        sis_prompt = _load_prompt_template('content2sis_scene_from_image.md').substitute()
        system_prompt = _load_prompt_template('content2sis_scene_system.md').substitute()
        # è¨ˆæ¸¬é–‹å§‹
        req_start = time.time()

        # Structured Output å‘¼ã³å‡ºã—
        sis_json, raw_text = self._ollama_chat_structured(
            messages=[
                {'role': 'system', 'content': system_prompt},
                {'role': 'user', 'content': sis_prompt}
            ],
            schema=scene_sis_schema,
            images=[image_base64]
        )
        req_duration = time.time() - req_start

        # scene_idã‚’ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å´ã§ç”Ÿæˆï¼ˆsis2sis.pyã¨åŒæ§˜ï¼‰
        sis_json['scene_id'] = self._generate_scene_id()
        sis_json['sis_type'] = 'scene'

        return ProcessingResult(
            success=True,
            data={'sis_data': sis_json, 'content': raw_text, 'content_format': 'json', 'prompt': sis_prompt},
            error=None,
            metadata={
                'content_type': 'image',
                'image_path': image_path,
                'image_file_size': os.path.getsize(image_path) if os.path.exists(image_path) else None,
                'image_base64_length': len(image_base64),
                'request_duration_sec': round(req_duration, 4),
                'timestamp': datetime.now().isoformat()
            }
        )
    
    def _process_text(self, text_path: str, **kwargs) -> ProcessingResult:
        """ãƒ†ã‚­ã‚¹ãƒˆâ†’SISï¼ˆStructured Output ã‚’ä½¿ç”¨ã€å®Œå…¨ãªSceneSISã‚¹ã‚­ãƒ¼ãƒã«æº–æ‹ ï¼‰"""
        # ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹ã®èª­ã¿è¾¼ã¿
        text_content = self._load_text_content(text_path)
        if not text_content:
            raise ValidationError(
                'Failed to load text content or empty file',
                error_code='TEXT_LOADING_FAILED'
            )

        # å®Œå…¨ãªSceneSISã‚¹ã‚­ãƒ¼ãƒã‚’å–å¾—
        scene_sis_schema = self._scene_sis_schema()
        sis_prompt = _load_prompt_template('content2sis_scene_from_text.md').substitute(
            text_json=json.dumps(text_content, ensure_ascii=False)
        )
        system_prompt = _load_prompt_template('content2sis_scene_system.md').substitute()

        sis_json, raw_text = self._ollama_chat_structured(
            messages=[
                {'role': 'system', 'content': system_prompt},
                {'role': 'user', 'content': sis_prompt}
            ],
            schema=scene_sis_schema
        )

        # scene_idã‚’ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å´ã§ç”Ÿæˆï¼ˆsis2sis.pyã¨åŒæ§˜ï¼‰
        sis_json['scene_id'] = self._generate_scene_id()
        sis_json['sis_type'] = 'scene'

        return ProcessingResult(
            success=True,
            data={'sis_data': sis_json, 'content': raw_text, 'content_format': 'json', 'prompt': sis_prompt},
            error=None,
            metadata={
                'content_type': 'text',
                'text_length': len(text_content),
                'timestamp': datetime.now().isoformat()
            }
        )
    
    def _check_server_and_model(self) -> None:
        """ã‚µãƒ¼ãƒãƒ¼ã¨ãƒ¢ãƒ‡ãƒ«ã®çŠ¶æ…‹ç¢ºèªï¼ˆOllamaç‰ˆï¼‰"""
        try:
            # Ollama ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ç¢ºèª
            v = requests.get(f"{self.api_config.ollama_uri}/api/version", timeout=10)
            if v.status_code != 200:
                raise ServerConnectionError("Ollama", self.api_config.ollama_uri)

            # ãƒ¢ãƒ‡ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèªï¼ˆtagsï¼‰
            tags = requests.get(f"{self.api_config.ollama_uri}/api/tags", timeout=10)
            if tags.status_code == 200:
                tj = tags.json() or {}
                models = [m.get('model') for m in tj.get('models', []) if isinstance(m, dict)]
                # ä¸€è‡´æ¡ä»¶: å®Œå…¨ä¸€è‡´
                if self.api_config.ollama_model not in (models or []):
                    # æœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ã‚‚ç”Ÿæˆã¯å‹•ãå ´åˆãŒã‚ã‚‹ãŒã€æ˜ç¤ºçš„ã«ã‚¨ãƒ©ãƒ¼ã«ã™ã‚‹
                    raise ModelNotLoadedError(self.api_config.ollama_model)
        except requests.exceptions.ConnectionError:
            raise ServerConnectionError("Ollama", self.api_config.ollama_uri)
    
    def _extract_sis_from_audio(self, audio_path: str) -> Dict[str, Any]:
        """éŸ³å£°ã‹ã‚‰ã®SISæŠ½å‡ºï¼ˆOllamaã§ã¯æœªã‚µãƒãƒ¼ãƒˆã®ãŸã‚ç°¡æ˜“å¯¾å¿œï¼‰"""
        # ã“ã“ã§ã¯æœªå¯¾å¿œã¨ã—ã¦æ˜ç¤ºã—ã€å°†æ¥çš„ã«Whisperç­‰ã¨ã®é€£æºã‚’æ¤œè¨
        raise GeNarrativeError(
            'Audio-to-SIS via Ollama is not supported in this build. Please use image/text SIS or provide a text summary of the audio.',
            error_code='AUDIO_SIS_NOT_SUPPORTED'
        )
    
    def _ollama_chat_structured(self, messages: list, schema: Dict[str, Any], images: Optional[list] = None) -> Tuple[Dict[str, Any], str]:
        """/api/chat ã‚’ç”¨ã„ãŸ Structured Output å‘¼ã³å‡ºã—ã€‚JSONã‚’å³å¯†ã«è¿”ã™ã€‚
        Returns: (sis_json, raw_text)
        """
        self._check_server_and_model()
        payload = {
            'model': self.api_config.ollama_model,
            'messages': messages.copy(),
            'stream': False,
            'format': schema,
            'options': {
                'temperature': 0
            }
        }
        # ç”»åƒãŒæ¸¡ã•ã‚ŒãŸå ´åˆã¯ user ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã® images ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«æ·»ä»˜
        if images:
            cleaned_images = []
            for img in images:
                if isinstance(img, str) and img.startswith('data:'):
                    try:
                        cleaned_images.append(img.split('base64,', 1)[1])
                    except Exception:
                        cleaned_images.append(img)
                else:
                    cleaned_images.append(img)

            for message in reversed(payload['messages']):
                if isinstance(message, dict) and message.get('role') == 'user':
                    existing = message.get('images')
                    if isinstance(existing, list):
                        message['images'] = existing + cleaned_images
                    else:
                        message['images'] = cleaned_images
                    break
        try:
            resp = requests.post(f"{self.api_config.ollama_uri}/api/chat", json=payload, timeout=180)
            if resp.status_code != 200:
                raise GeNarrativeError(f"HTTP {resp.status_code}: {resp.text}")
            rj = resp.json() or {}
            content = ''
            # chat å¿œç­”ä»•æ§˜: message.content ã«JSONæ–‡å­—åˆ—
            msg = rj.get('message') or {}
            content = msg.get('content') or ''
            if not content:
                # ä¸€éƒ¨ãƒ¢ãƒ‡ãƒ«å®Ÿè£…å·®ç•°ã«å‚™ãˆ fallback
                content = rj.get('response') or ''
            if not content:
                raise GeNarrativeError('Empty content from Ollama chat')
            # JSONã¨ã—ã¦å³å¯†ã«ãƒ‘ãƒ¼ã‚¹
            sis_json = json.loads(content)
            return sis_json, content
        except requests.exceptions.Timeout:
            raise GeNarrativeError('Request timeout (3 minutes)')
        except json.JSONDecodeError as e:
            raise ValidationError(f'Structured output is not valid JSON: {e}', error_code='STRUCTURED_JSON_INVALID')

    def _scene_sis_schema(self) -> Dict[str, Any]:
        """å®Œå…¨ãªSceneSISã®JSONã‚¹ã‚­ãƒ¼ãƒã‚’è¿”ã™ï¼ˆsis2sis.pyã¨åŒã˜æ§‹é€ ï¼‰"""
        # SceneSIS_semantics.jsonã‚’èª­ã¿è¾¼ã‚€
        schema_path = Path(__file__).parent / 'schemas' / 'SceneSIS_semantics.json'
        
        if schema_path.exists():
            with open(schema_path, 'r', encoding='utf-8') as f:
                semantics_schema = json.load(f)
        else:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚¹ã‚­ãƒ¼ãƒ
            semantics_schema = {
                "type": "object",
                "properties": {
                    "common": {"type": "object"},
                    "text": {"type": "object"},
                    "visual": {"type": "object"},
                    "audio": {"type": "object"}
                },
                "required": ["common", "text", "visual", "audio"]
            }
        
        return {
            "type": "object",
            "properties": {
                "sis_type": {
                    "type": "string",
                    "const": "scene",
                    "description": "Must be 'scene'"
                },
                "scene_id": {
                    "type": "string",
                    "description": "Identifier for this scene (assigned by the system)"
                },
                "summary": {
                    "type": "string",
                    "description": "Brief summary of what happens in this scene"
                },
                "semantics": semantics_schema
            },
            "required": ["sis_type", "scene_id", "summary", "semantics"]
        }

    def _generate_scene_id(self) -> str:
        """scene_idã‚’ç”Ÿæˆï¼ˆsis2sis.pyã¨åŒã˜å½¢å¼ï¼‰"""
        return datetime.now().strftime("scene_%Y%m%d_%H%M%S_%f")

    

    def _schema_field_guide_template(self, schema: Dict[str, Any]) -> str:
        """JSON Schema ã‚’ã‚‚ã¨ã«LLMãŒç†è§£ã—ã‚„ã™ã„ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆJSONã‚’ç”Ÿæˆ"""
        try:
            def build(prop: Dict[str, Any]) -> Any:
                if not isinstance(prop, dict):
                    return "value"

                desc = (prop.get('description') or '').strip()
                prop_type = prop.get('type')
                examples = prop.get('examples')
                if isinstance(examples, list) and examples:
                    example_value = examples[0]
                    # JSON Schema stores examples as JSON values; ensure strings remain strings
                    return example_value

                if prop_type == 'object' and isinstance(prop.get('properties'), dict) and prop['properties']:
                    return {k: build(v) for k, v in prop['properties'].items()}

                if prop_type == 'array':
                    item_prop = prop.get('items') if isinstance(prop.get('items'), dict) else None
                    item_value = build(item_prop) if item_prop else (desc or 'item description')
                    if isinstance(item_value, dict):
                        return [item_value]
                    if isinstance(item_value, list):
                        return item_value
                    return [item_value or (desc or 'item description')]

                return desc or (f"{prop_type} value" if prop_type else 'value description')

            props = (schema or {}).get('properties', {})
            guide_template = {key: build(prop) for key, prop in props.items()}
            return json.dumps(guide_template, ensure_ascii=False, indent=2)
        except Exception:
            return ''
    
    def _extract_sis_from_text(self, text_content: str) -> Dict[str, Any]:
        """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã®SISæŠ½å‡º"""
        self._check_server_and_model()

        sis_prompt = _load_prompt_template('content2sis_legacy_sis_from_text.md').substitute(
            text_content=text_content
        )

        try:
            payload = {
                'model': self.api_config.ollama_model,
                'prompt': sis_prompt,
                'stream': False,
                'options': {
                    'temperature': 0.7,
                    'num_predict': 800
                }
            }
            response = requests.post(
                f"{self.api_config.ollama_uri}/api/generate",
                json=payload,
                timeout=180
            )
            if response.status_code == 200:
                result = response.json() or {}
                text = result.get('response') or ''
                if text:
                    sis_data = self._parse_sis_json_response(text)
                    if sis_data:
                        sis_data['extraction_time'] = datetime.now().isoformat()
                        return sis_data
                    else:
                        raise ValidationError('Failed to parse JSON from response')
                else:
                    raise GeNarrativeError('Empty response from Ollama')
            else:
                raise GeNarrativeError(f'HTTP {response.status_code}: {response.text}')
        except requests.exceptions.Timeout:
            raise GeNarrativeError('Request timeout (3 minutes)')
    
    def _load_and_encode_image(self, image_path: str) -> Optional[str]:
        """ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰"""
        try:
            with open(image_path, 'rb') as img_file:
                image_base64 = base64.b64encode(img_file.read()).decode('utf-8')
            return image_base64
        except Exception as e:
            self.logger.log_error('_load_and_encode_image', str(e))
            return None
    
    def _load_text_content(self, text_path: str) -> Optional[str]:
        """ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’èª­ã¿è¾¼ã¿"""
        try:
            with open(text_path, 'r', encoding='utf-8') as f:
                content = f.read().strip()
            return content if content else None
        except Exception as e:
            self.logger.log_error('_load_text_content', str(e))
            return None
    
    def _parse_sis_json_response(self, generated_text: str) -> Optional[Dict[str, Any]]:
        """ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰JSONã‚’æŠ½å‡ºãƒ»è§£æ"""
        try:
            # 1) å‰å‡¦ç†: LLMãƒˆãƒ¼ã‚¯ãƒ³ã‚„ã‚³ãƒ¼ãƒ‰ãƒ•ã‚§ãƒ³ã‚¹ã®é™¤å»
            text = (generated_text or '').strip()
            for token in (
                '<bos>', '<eos>', '<pad>', '<unk>',
                '<start_of_turn>', '<end_of_turn>',
                '<start_of_turn>model', '<start_of_turn>user', '<start_of_turn>assistant',
            ):
                text = text.replace(token, '')

            # ã‚³ãƒ¼ãƒ‰ãƒ•ã‚§ãƒ³ã‚¹ã®ä¸­èº«ã‚’å„ªå…ˆ
            if '```json' in text:
                try:
                    inner = text.split('```json', 1)[1]
                    inner = inner.split('```', 1)[0]
                    text = inner.strip()
                except Exception:
                    pass
            elif '```' in text:
                try:
                    inner = text.split('```', 1)[1]
                    inner = inner.split('```', 1)[0]
                    text = inner.strip()
                except Exception:
                    pass

            # 2) ã¾ãšã¯ç´ ç›´ã«ãƒ‘ãƒ¼ã‚¹
            try:
                return json.loads(text)
            except json.JSONDecodeError:
                pass

            # 3) ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: æœ€åˆã® '{' ã‹ã‚‰å¯¾å¿œã™ã‚‹ '}' ã¾ã§ã®ãƒ–ãƒ­ãƒƒã‚¯ã‚’æŠ½å‡ºï¼ˆå˜ç´”ãªæ‹¬å¼§å¯¾å¿œï¼‰
            start = text.find('{')
            if start != -1:
                depth = 0
                end = -1
                for i in range(start, len(text)):
                    ch = text[i]
                    if ch == '{':
                        depth += 1
                    elif ch == '}':
                        depth -= 1
                        if depth == 0:
                            end = i + 1
                            break
                if end != -1:
                    candidate = text[start:end]
                    try:
                        return json.loads(candidate)
                    except json.JSONDecodeError:
                        # è»½å¾®ãªæœ«å°¾ã‚«ãƒ³ãƒã®å‰Šé™¤ãªã©ã®ç°¡æ˜“ä¿®æ­£
                        candidate_fixed = candidate.replace(',}', '}').replace(',]', ']')
                        try:
                            return json.loads(candidate_fixed)
                        except Exception:
                            pass

            # 4) å¤±æ•—
            raise json.JSONDecodeError('Failed to extract valid JSON block', text, 0)

        except json.JSONDecodeError as e:
            self.logger.log_error('_parse_sis_json_response', f'JSON decode error: {e}')
            return None
        except Exception as e:
            self.logger.log_error('_parse_sis_json_response', f'Parsing error: {e}')
            return None


# ========================================
# çµ±ä¸€ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆé–¢æ•°
# ========================================

def extract_sis_from_content(
    content_path: str,
    content_type: str = None,
    api_config: Optional[APIConfig] = None,
    processing_config: Optional[ProcessingConfig] = None,
    logger: Optional[StructuredLogger] = None
) -> Dict[str, Any]:
    """
    çµ±åˆã•ã‚ŒãŸSISæŠ½å‡ºé–¢æ•°
    
    Args:
        content_path: ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        content_type: ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¿ã‚¤ãƒ— ('audio' | 'image' | 'text' | None)
        api_config: APIè¨­å®š
        processing_config: å‡¦ç†è¨­å®š
        logger: ãƒ­ã‚¬ãƒ¼
    
    Returns:
        çµ±ä¸€ã•ã‚ŒãŸæˆ»ã‚Šå€¤è¾æ›¸
    """
    extractor = SISExtractor(api_config, processing_config, logger)
    result = extractor.process(content_path, content_type)
    return result.to_dict()


# ========================================
# æ—¢å­˜é–¢æ•°ï¼ˆå¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ï¼‰
# ========================================

def audio2SIS(
    audio_path: str = "/app/shared/music_0264b049.wav",
    api_uri: str = "http://unsloth:5006",
    model_name: str = "unsloth/gemma-3n-E4B-it"
) -> Dict[str, Any]:
    """
    éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰SISæŠ½å‡ºï¼ˆå¾Œæ–¹äº’æ›æ€§ï¼‰
    """
    api_config = APIConfig(unsloth_uri=api_uri, model_name=model_name)
    return extract_sis_from_content(audio_path, 'audio', api_config)


def image2SIS(
    image_path: str = "/app/shared/image/story_image_20250726_094413.png",
    api_uri: str = "http://unsloth:5006",
    model_name: str = "unsloth/gemma-3n-E4B-it"
) -> Dict[str, Any]:
    """
    ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰SISæŠ½å‡ºï¼ˆå¾Œæ–¹äº’æ›æ€§ï¼‰
    """
    api_config = APIConfig(unsloth_uri=api_uri, model_name=model_name)
    return extract_sis_from_content(image_path, 'image', api_config)


def text2SIS(
    text_path: str = "/app/shared/text/text_20250804_230132.txt",
    api_uri: str = "http://unsloth:5006",
    model_name: str = "unsloth/gemma-3n-E4B-it"
) -> Dict[str, Any]:
    """
    ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰SISæŠ½å‡ºï¼ˆå¾Œæ–¹äº’æ›æ€§ï¼‰
    """
    api_config = APIConfig(unsloth_uri=api_uri, model_name=model_name)
    return extract_sis_from_content(text_path, 'text', api_config)


def speech2text(
    audio_path: str,
    api_uri: str = "http://unsloth:5006",
    model_name: str = "unsloth/gemma-3n-E4B-it"
) -> Dict[str, Any]:
    """
    éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºï¼ˆæœ¬ãƒ“ãƒ«ãƒ‰ã§ã¯æœªã‚µãƒãƒ¼ãƒˆï¼‰

    Note:
        æœ¬é–¢æ•°ã¯ Unsloth ã‚µãƒ¼ãƒã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã—ãŸãŒã€è¦ä»¶ã«ã‚ˆã‚Šç„¡åŠ¹åŒ–ã—ã¾ã—ãŸã€‚
        ä»£ã‚ã‚Šã«å¤–éƒ¨ã®éŸ³å£°èªè­˜ï¼ˆä¾‹: Whisperï¼‰ã‚’å°å…¥ã™ã‚‹ã‹ã€ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ¥é€”ç”¨æ„ã—ã¦ãã ã•ã„ã€‚

    Raises:
        GeNarrativeError: ç¾åœ¨æœªã‚µãƒãƒ¼ãƒˆã§ã‚ã‚‹æ—¨ã®ä¾‹å¤–
    """
    raise GeNarrativeError(
        'speech2text() is disabled: Unsloth is not used in this build. '
        'Please provide text manually or integrate a speech-to-text service (e.g., Whisper).',
        error_code='SPEECH_TO_TEXT_NOT_SUPPORTED'
    )


# ========================================
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°ï¼ˆæ—¢å­˜ã®ã‚‚ã®ã‚’çµ±åˆï¼‰
# ========================================

def save_sis_to_file(sis_data: Dict[str, Any], output_path: str) -> bool:
    """
    SIS data to file in JSON format.
    """
    try:
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(sis_data, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ SIS data saved to: {output_path}")
        return True
        
    except Exception as e:
        print(f"âŒ Failed to save SIS data: {e}")
        return False


def json2jsonl(json_file_path: str, jsonl_file_path: str = None) -> bool:
    """
    Convert JSON file to JSONL format.
    """
    try:
        if jsonl_file_path is None:
            base_name = os.path.splitext(json_file_path)[0]
            jsonl_file_path = f"{base_name}.jsonl"
        
        with open(json_file_path, 'r', encoding='utf-8') as f:
            json_data = json.load(f)
        
        os.makedirs(os.path.dirname(jsonl_file_path), exist_ok=True)
        with open(jsonl_file_path, 'w', encoding='utf-8') as f:
            json.dump(json_data, f, ensure_ascii=False, separators=(',', ':'))
            f.write('\n')
        
        print(f"ğŸ”„ JSON to JSONL conversion completed")
        print(f"   Input:  {json_file_path}")
        print(f"   Output: {jsonl_file_path}")
        return True
        
    except FileNotFoundError:
        print(f"âŒ JSON file not found: {json_file_path}")
        return False
    except json.JSONDecodeError as e:
        print(f"âŒ Invalid JSON format: {e}")
        return False
    except Exception as e:
        print(f"âŒ JSON to JSONL conversion failed: {e}")
        return False
